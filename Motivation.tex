\section{Motivation}
\label{sec:motivation}

\bx{A container-based cloud is a promising technology to support SOA, the new trend in software industry.} container-based clouds provide a finer granularity management of applications compared with VM-based clouds \cite{:2017ff}. Such finer granularity management improves the utilization of resources and minimizes energy consumption of data centers. Therefore, container-based clouds not only increase the profit for cloud providers but reduces the cost of cloud users as well.

\bx{Even though container-based clouds has many advantages to achieve energy-efficiency, it is more challenging in optimizing the placement of applications than in VM-based clouds.} \textbf{First}, we cannot use existing VM-based energy models for the container-based clouds. Current VM-based energy models represent a single level of placement: VM-PM while the container-based clouds need a two-level energy model representing the placement between container-VM and the placement between VM-PM. However, the two-level energy model is more complicated than the single-level energy model. 
\textbf{Second}, current VM-based optimization approaches \cite{Beloglazov:2010dt, Liu:2013kl} formulate the placement of applications as a bin packing problem. Most VM-based approaches use bin-packing heuristics such as First Fit \cite{Dosa:2013ie} that are designed for the problem of single-level placement. Since container-based clouds have two-level placement,  bin-packing heuristics can rarely achieve the global optimal solution in container-based clouds. 


In recent years, Evolutionary Computation (EC)-based approaches have been applied to bilevel problems in other areas such as logistics distribution centers and have shown promising results \cite{Angelo:2013ee, Sinha:2017et, Deb:2010in}. However, EC-based approaches have not been used to solve the placement of applications in container-based clouds. Therefore, we need to study how to design representations and specific genetic operators for adapting EC algorithms to container-based clouds.  The above three issues exist in all three main scenarios of placement in container-based clouds. 

 \bx{Besides the above issues, other specific issues exist in three main scenarios of placement of applications.} \textbf{Initial placement of applications} deploys applications when data centers receive a number of requests. We need to investigate a scalable EC-based optimization algorithm to further minimize the energy consumption when placing over one thousand of applications in PMs. 
\textbf{Periodic placement of applications} migrates applications to fewer PMs to optimize energy consumption and migration cost with consideration of workload. We need to take workload into account in a new model for multi-objective (energy and migration cost) optimization. 
Meanwhile, we will investigate how to design an EC-based approach to solve the multi-objective bilevel placement. 
% Apart from lacking of multi-objective energy model, current VM-based approaches do not consider the vary of workload of applications. An ideal solution would achieve minimum energy consumption and minimum cost of migration of applications during the daily operations of data centers.
\textbf{Dynamic placement of applications} is capable of dynamically allocating applications when abnormal events such as overloading and under-loading \cite{Beloglazov:2013ht} happen in data centers. Unlike the previous two scenarios, dynamic placement requires fast allocation for optimizing energy consumption. A genetic programming \cite{Banzhaf:1998wc} hyper-heuristic (GP-HH) is a promising technology that
has been used in many dynamic problems such as dynamic job shop scheduling \cite{Nguyen:2014eu}. GP-HH is based on learning patterns from previous good solutions and can automatically generate heuristics. Hence,  GP-HH can allocate applications quickly and optimally in terms of energy consumption. However, the complex learning patterns from previous good solutions are challenging in dynamic placement because different types of workload exist and some of them are unpredictable. In summary, all these issues are critical and need solving in order to achieve energy efficiency in container-based clouds. Therefore, we need to design bilevel energy models and applying EC-based optimization algorithms for the placement of applications in container-based clouds. 

% GP-HH GP-HH  that Therefore, GP-HH is ideal for the dynamic placement of application problem.

% Abnormal events indicate that the performance of an application is degrading, therefore, the application requires a quick allocation to other PMs. Most VM-based studies do not consider different types of workload of application and only use simple bin-packing heuristics which lead to low energy efficiency.

% Through the research on energy-efficient server consolidation in container-based clouds, we expect to contribute to better energy efficiency 
% by designing bilevel models of container-based clouds and EC-based optimization algorithms.


% \bx{This section identifies the research gaps in  resource management of container-based data centers.}
% We will discuss the gaps from three placement decision scenarios: initial placement of application, periodic placement of application, and dynamic placement of application.

% \subsection{Initial placement of application}
% \bx{initial placement of application deploys applications when data centers receive a number of requests.} The placement can be seen as a static server consolidation problem. To reduce energy, the strategy allocates applications to a minimum number of physical machines (PMs). For VM-based and container-based clouds, the energy models are different.
% The optimization process can be described as: given a number of  PMs represented as resources (e.g CPU cores and RAM etc);  requested applications (wrapped with VMs or container) represented as aforementioned resources; the objective is to allocate these applications into a minimum number of PMs. The decision variable is the location of each application. The basic constraint is that the aggregative resources of hosted VMs cannot exceed the PM's resource capacity.
% The strategies in VM-based cloud and container-based clouds are different. In VM-based cloud, requested applications (wrapped with VMs) are placed into a minimum number of PMs. The problem in VM-based cloud is often modeled as a bin packing problem \cite{Xiong:2014jq}, with VMs represent items and PMs represent bins. The complexity is NP-hard \cite{Hochbaum:1996ts}. 
% \bx{In a VM-base Cloud}, the energy model of initial placement of application can be seen as a vector bin packing problem \cite{Leinberger:1999fs}, applications (wrapped with VMs) are packed in PMs (detailed discussion is in Section \ref{sec:vector_bin_packing}).

% \bx{In contrast, in a container-based clouds, the energy model can be seen as a bilevel optimization problem \cite{Colson:2007bu} where each level is treated as a bin packing problem.} The lower level optimizes the placement of containers to VMs and the upper level optimizes the placement of VMs to PMs. The advantage the bilevel model is that the interaction of container-VM and VM-PM placement is considered, so that the global optimal can be achieved.

% \bx{Two reasons motivate us to solve the initial placement of application in container-based clouds.} 
% First, currently, no research has considered the initial placement of application as a bilevel optimization problem. Therefore, it needs to propose a new bilevel energy model. A bilevel model - includes energy model, workload model and prices model - represents the relationship between container, VMs, and energy consumption. Current VM-based models cannot be directly applied because container-based model has two levels of placement. In addition, current VM-based models do not consider the overhead of VM hypervisor because for VM-based cloud there is no better ways to avoid the overhead. However, in container-based clouds, the overhead of VMs can be mitigated by reducing the number of VMs. This can be achieved by consolidating containers to fewer VMs. Furthermore, many VM-based models do not consider a balance between CPUs and memories. The balance is crucial \cite{Tomas:2013iv} in improving utilization of PMs, because the balance in a PM increases the probability of being able to allocating a new application.

% \bx{Second, bilevel optimization is known to be strongly NP-hard \cite{Sinha:2013tn}.} Even in the simplest case of linear  bilevel programs, where the lower level problem has a unique optimal solution for all the parameters, it is not likely to find a polynomial algorithm that can find the global optimum solution. The proof for the non-existence of a polynomial time algorithm for linear bilevel problems can be found in \cite{Deng:1998fk}. In contrast, evolutionary computation (EC) is a population-based search mechanism which has been proposed to solve bilevel optimization problems \cite{Wang:2008kb, Wang:2011di, Angelo:2013ee}. EC algorithms have shown promising performance bilevel problems. Therefore, we will investigate EC-based approaches on bilevel problem.

% The optimization interact with VMs and containers, therefore, it cannot be optimized separately. An additional constraint is that each container has its OS requirement which makes them cannot be simply packed into homogeneous VMs. 

% \bx{Container-based placement can be seen as a bilevel optimization problem \cite{Colson:2007bu} where each level is bin packing problem.} Because of the problem structure has changed, previous VM-based approaches cannot be directly applied on the problem. In addition, currently, there is no study considers the container-based placement as a bilevel problem. The advantage of considering it as a bilevel problem is that containers and VMs can cooperate to achieve lower energy consumption. However, the \emph{optimization of joint placement of container and VMs} is very difficult because of the nature of bilevel problem.

% The hierarchy of bilevel optimization makes problems non-convex and strongly NP-hard \cite{Vicente:1994ie}.
% The placement problem in the VM context has been studied for years \cite{Xu:2010vh, Gao:2013gg, Ferdaus:2014ep} and it is often modeled as a bin packing problem . This is because VMs and PMs are naturally modeled as items and bins. Furthermore, server consolidation and bin-packing have the same optimization objective: minimize the number of bins/PMs. The complexity of bin-packing problem is NP-hard which is NP-hard \cite{Hochbaum:1996ts} which means it is extreme time-consuming to find its optimal solution when the number of decision variables is large. However, most research focus on VM-based server consolidation and these methods cannot be directly applied on container-based consolidation because of the different structure.

% \bx{Only few research focus on container-based server consolidation problem. One of research is from Piraghaj and et al \cite{Piraghaj:2015uf}.} They propose a simple heuristics on two-step allocation, thus, did not consider the interaction between two levels (see detailed discussion in Section \ref{container-based-placement}). 
% In addition, their resource allocation system completely relies on dynamic placement of application without using static methods. Although their system can execute allocation fast, the energy efficiency cannot be guaranteed. 
% Another research \cite{Mann:2016hx} is the earliest study which realizes two-level of placement should be considered together because they are interact with each other. They apply a fixed VM placement algorithm and considering a series of VM selection algorithms. The results also proves that the interaction between two placement cannot be ignored. 


% \subsection{Periodic placement of application}



% For the lower level of allocation, the objective is to maximize the utilization of resources (e.g a balanced utilization among several resources), while the upper level objective is to minimize the number of PMs. 
% \bx{After initial placement, periodic placement of application is a routine process that takes existing applications' placement, re-placing them to PMs to optimize the energy consumption.} A technology called live migration can be used to re-place the applications' placement from one PM to another. Live migrations are very expensive since they consume network bandwidth and use the resources on both host PM and targeted PM. Therefore, periodic placement of application is a multi-objective task which considers minimizing migration of applications and minimizing the overall energy consumption. Resolving the bi-level multi-objective problem will lead to a high utilization of PMs but it is very challenging.

% \bx{Two reasons motivate us to explore solutions for periodic placement of application in a container-based clouds}. 
% \textbf{First}, no research has considered the periodic placement of application in a container-based clouds as a bilevel multi-objective optimization problem. The multi-objective bilevel problem has two potentially conflicting objectives: reducing the number of migration and minimizing the energy consumption.
% \textbf{Second}, not many research have considered the robustness of placement. The robustness of placement means the placement is resilient enough to handle the fluctuate workloads without making too many further adjustments. To achieve robustness of placement, periodic placement of application must consider the combination of various workloads and the reserved resources on PMs. Currently, most research simplified workloads as static (remains a constant value throughout its life cycle) \cite{Viswanathan:2012ej, Chen:2011fl,Feller:2011vs} for the sake of simplicity. The placement is easy to affect by fluctuations which leads to higher energy consumption. Therefore, we will consider various types of workload to improve the robustness of placement.
% For example, for periodic workload, the average value within a period of time will be considered. 

% \bx{In our research, we will consider periodic placement of application as a multi-objective problem with various types of workload \cite{Fehling:2014tl}.} Specifically, complementary workloads can be combined so that it can potentially reduce the migration in the future. Thus, the applications are consolidated in a more robust way. 

% However, in real life, workloads vary with time. According to Fehling , applications' workload are roughly classified into five categories: static, periodic, once-in-a-life-time, continuously changing, and unpredictable. 

% They cannot be treated as a static value in a server consolidation because Therefore, it increases the cost in the future. 




% Only a few research consider applying different strategies on different workloads \cite{Meng:2010gh}. Their experiments showed promising results, however, they only mapped paired workloads which can be further improved by combining multiple workloads.
% \subsection{dynamic placement of application of application}


% \bx{dynamic placement of application is applied on overloading and underloading scenarios which need an immediate reaction on the placement of an application \cite{Beloglazov:2013ht}.} Overloadding and underloading happened when applications are released from PMs or applications are facing a burst of workload. In overloading scenario, PMs are running out of resources which means the applications' performance degraded. The degradation will bring financial punishment for Cloud providers. In underloading scenario, PMs are running in a low utilization which leads to the waste of energy. At these states, it is ideal that applications inside the PM will be placed to other PMs to quickly resolve the problems.
% Overloading is a scenario that the workloads exceed the capacity of its host PM. Hence, one or more applications will be migrated to other PMs. Underloading is when a PM runs in a low utilization, all the applications inside it will be moved to other PMs, so that the PM can be turned off. The common operation in these two scenarios are the dynamic placement of application \cite{Xiao:2015ik}. dynamic placement of application places one application each time in an on-line manner. 

% \bx{Three reasons motivates us to explore solutions for dynamic placement of application}. 
% \textbf{Firstly}, no research has considered dynamic placement of application in container-based clouds as a bilevel problem. Current approaches \cite{Piraghaj:2016bw} consider two placements as separate tasks. 
% \textbf{Secondly}, current VM-based dynamic placement of application approaches typically applied either simple bin-packing algorithms such as First Fit or manually designed heuristics. Simple bin-packing algorithms may perform poorly because application placement is more complicated than bin-packing \cite{Mann:2015ua}. Therefore, even for the placement of VMs to PM, it is difficult to reach a global optimal solution. \textbf{Thirdly}, manually designed heuristics may not be general (in terms of decision variables and constraints) because they are designed for specific conditions and constraints \cite{Jung:2010dt}, e.g considered the network topology in data centers. We want to develop a hyper-heuristic approach which can automatically generate good heuristics based the knowledge learned from previous placement solutions.

% The hyper-heuristic can learn from previous good solutions as well as the features of various workloads so that the dispatching rules can be applied with any conditions and constraints. 
% on one hand, dynamic placement of application allocates an application at a time to meet the requirement of fast reaction. On the other hand, it only considers the best placement of the current application using either simple bin-packing algorithms such as First Fit or manually design heuristics. Simple bin-packing algorithms may perform poorly because application placement is more complicated than bin-packing \cite{Mann:2015ua}, while manual designed heuristics may not be general because they are designed for specific conditions and constraints\cite{Jung:2010dt}.
% Mann's research  showed, server consolidation is a lot harder than bin-packing problem because of the multi-dimensional of resources, heterogeneous PMs, migration cost etc. 


% In summary, shortcomings of current resource management in container-based clouds increase the energy consumption of a cloud data center. Therefore, our goal is to reduce the energy consumption by overcoming these limitations in each of placement decision scenario.


% \bx{These challenges motivate us to develop a hyper-heuristic approach which can automatically generate heuristics for quickly placing.} 

% In addition, in container-based clouds, the placement target is on containers and the destination is a suitable VM. However, if no VM can accommodate a container, a new VM must be created, which incurs a second level of deployment.

% \bx{In summary, this thesis aims at improving the energy efficiency in a container-based clouds data center.} The gaps in three resource management processes motivate us to address three issues:
% \begin{itemize}
% 	\item Develop an algorithm for the joint placement of containers and VMs.
% 	\item Develop an algorithm for multi-objective joint placement of containers and VMs with consider various workloads.
% 	\item Develop a hyper-heuristic for dynamic placement of application.
% \end{itemize}




% The motivation for this thesis mainly includes two parts, in the first part, we illustrate the roots of container-based server consolidation problem. In the second parts, we explain the motivations for the objectives.

% \subsection{Motivation For Container-based Server Consolidation Problem}

% Server consolidation \cite{Zhang:2010vo} resolves the low utilization problem by gathering applications or VMs into a fewer number of physical machines (PMs), so that the resource utilization of PMs are maintained at a high level. In the meanwhile, idle servers are turned off to save energy. Traditional server consolidation is VM-based, in comparison with 
% a server host a single application, it can dramatically improve the resource utilization. 


% \begin{figure}
% 	\centering
% 	\includegraphics[width=0.3\textwidth]{pics/problem_flow.png}
% 	\caption{The root of container technology}
% 	\label{fig:root}
% \end{figure}
% \begin{enumerate}
% \item Container is a new virtualization technology which provides an operating level of virtualization.
% % Figure \ref{fig:root} illustrates the root of container technology from an energy efficient point of view. 

% In order to solve this problem, overbooking strategy tends to place more VMs than the server's maximum capacity. However, this technique is highly relied on workload prediction on the application running in a VM. Otherwise, servers are easily overloaded. Container technique can improve the utilization by further partitioning VM into resource isolated chunks. Therefore, multiple applications can share the same VM. This technique avoids the prediction of workload as well as improving the utilization. 



% This container technology brings many advantages to current Cloud industry\cite{Felter:2015ki}but it also brings difficulties for server consolidation. Container-based server consolidation adds another level of abstraction which makes it a two-level vector bin-packing problem.
% Therefore, it motivates us to provide \emph{global optimized} resource allocation solution for container-based data centers.

% \end{enumerate}


% \subsection{Motivation For Research objectives}
% Cloud data center has a high dynamic nature where it constrantly receives new requests for resource provisioning and releases old current resources. Therefore, a data center needs different strategies to
% handle different scenarios. 

% \textcolor{Maroon}{In this thesis, we aim at providing a series of approaches to continuously optimize the joint allocation of VMs and containers which involves with three scenarios: initial placement of application, periodic consolidation, and dynamic consolidation.} Different stages have distinct goals, therefore, they are considered as separated research questions. 

% \begin{enumerate}
% \item Joint allocation of containers and VMs (initial placement of application), \\
% \textcolor{Maroon}{Joint allocation of containers and VMs is the first task when a data center receives new application deployment requests.} At this stage, a set of containers is allocated to a set of VMs and these VMs are allocated to a set of PMs. This task is challenging because the problem is a bilevel optimization where each level is a bin packing problem. Exhaustive search of entire solution space is practically impossible, for the number of possible permutation of solution is huge. Current approaches \cite{Piraghaj:2016bw,Hindman:2011ux} use simple heuristics such as First Fit to solve the problem. These greedy-based heuristics do not consider the complex structure of the problem, therefore, often reach a local optimal solution.

% Only a few research focus on this  problem, Piraghaj \cite{Piraghaj:2016bw} designs a dynamic allocation system. She proposes a two-step procedure. Since, these two-level structure interact each other, separate solution certainly leads to a local optima. Therefore, in this thesis, we will solve the problem simutaneously.
% Most importantly, and therefore can not be solved separately. This is the first research that consider server consolidation has a bi-level optimization problem \cite{Wen:1991kt}. 

% In this objective, we will establish the fundamental concepts in studying this joint allocation of containers and VMs including new problem models: price and power model, new problem constraints, and optimization objectives. The major challenges for this objective is to design representations and several EC approaches to solve this problem. More specifically, in designing the EC approach, new search mechanisms, operators will be designed and new representations will be proposed to fit the problem. 

% This task is challenging, since a representation can highly affect the performance of consolidation \cite{SoteloFigueroa:2013be}. 

% \item Periodic consolidation, \\
% \textcolor{Maroon}{A periodic consolidation is conducted to improve the global energy efficiency in a periodical fashion.} Data center constantly receives new allocations, releasing of old resources. These changing degrades the compact structure of a data center. Therefore, the data center needs a global optimization to improve the overall energy efficiency.

% The challenges are three folds, firstly, similar with initialization problem, the problem has two level of allocations and they interact with each other. Secondly, like VM-based consolidation, Container-based consolidation is considered as a multi-objective problem with minimization of migration cost as well as keeping a good energy efficiency. In bilevel optimization, multi-objective can be defined in either or both level, therefore, it further increases the complexity. Thirdly, consolidation needs to consider different types of workload which may lead to more migrations in the future(\textcolor{Maroon}{NEED MORE EXPLANATION}).

% \item Dynamic consolidation,\\
% Dynamic It takes one container and allocates it to VMs. Since the size of container can be dynamically adjusted, when the an application is under-provision or over-provision, the original container is halted, resized and re-allocated. Hence, there is a need to allocate this new container in real time.

% To solve a dynamic consolidation, heuristics and dispatching rules are often used \cite{Sarin:2011fu, Shi:2011ke, Forsman:2015ca, Beloglazov:2012ji}.  In this scenario, a dispatching rule is considered as a function that determines the priorities of VMs that a container can be placed. However, dynamic placement of application is much complex than bin-packing problem \cite{Mann:2015ua}. Because of its dynamic nature, human designed heuristics are ill-equipped in approximating solutions when the environment has changed \cite{SoteloFigueroa:2013be}. 

% Hyper-heuristic methods, sepcifically, Genetic Programming (GP) technique \cite{Banzhaf:1998wc} can learn from the best previous allocation and automatically evolves dispatching rules to solve this problem. GP has been applied in generating dispatching rules for bin-packing problem \cite{Burke:2006ei, SoteloFigueroa:2013be} and other scheduling problems \cite{Nguyen:2014eu}. The results have shown promising results.

% There are mainly two challenges, first, it is difficult to identify the related factors that construct the heuristic. Factors or features are the building blocks of heuristics. It is a difficult task because the relationship between a good heuristic and features are not obvious. Second, representations provide different patterns to construct dispatching rules. It is also unclear what representation is the most suitable for the consolidation problem.


% and representations must be proposed to capture the characteristic of the joint allocation. 
% 	and the VMs are allocated to physical machines in the second step. Because of the complexity, previous research
% 	only considers the first step. They map the incoming tasks into predefined categories and based on the characteristic of the categories, the size of new virtual machines' resources are decided. After each tasks have chosen its VM type, they are allocated to virtual machines using a lightweight heursitic algorithm. 
% 	We intend to apply an EC-based approach to solve this problem by proposing a coevolutionary that simuetiously decide the virtual machine type as well as the allocation of VMs.


% \item Large-scale of static server consolidation problem, \\
	% In this case, initialization and periodic consolidation are belonged to this category. 
	% Since Cloud data center typically has hundreds of thousands PMs and more, static server consolidation is always very challenging. Many approaches have been proposed in the literature to resolve the problem. There are mainly two ways, both relied on distributed methods, hierarchical-based \cite{Jung:2010dt, Moens:2011gk} and agent-based management systems \cite{Yazir:2010bk}.
	% The major problem in agent-based systems is that agents rely on heavy communication to maintain a high-level utilization. Therefore, it causes heavy load in the networking. 
	% Hierarchical-based approaches are the predominate methods. In essence, these approaches are centralized methods where all the states of PMs within its region are collected and analyzed. The major disadvantage of hierarchical-based approaches is that it only provides local solutions. In fact, it is infeasible and unnecessary to check all the states of PMs since the search space is too large and most PMs do not need a change. This idea
	% motivates a way to improving the effectiveness is to reduce the number of variables so that the search space is narrowed. In this thesis, we are going to investigate the way to eliminate the redundant information.
% \end{enumerate}



% Traditional Cloud computing offers three services models: Infrastructure as a Service (IaaS), Platform as a Service (PaaS) and Software as a Service (SaaS). Both IaaS and PaaS describe how does a service provider use the cloud resources. The main difference of these two models are  
% IaaS allows service providers to manage the low-level details including the operating system and libraries. While, PaaS provides a higher level of abstraction where users only focus on the application development without caring the underlying operating system and system-level of resources such as CPU cores and memories. However, one drawback of PaaS is that cloud users must make sure their applications are complete compatible with the platform. And in many of the cases, it is not the situation. In order to solve this problem, a container-based virtualization technology starts to reform the Cloud industry. Container as a Service (CaaS) 
% is a new concept but it has been used in industry for many years. Containers provide an operating system-level of isolation environment for applications. It does not need a hypervisor but complete rely on the operating system. 


% This exciting new technology has bring so many advantages for both Cloud users and Cloud providers. From the providers' perspective, In a large system, running VMs means there are probably many same operating systems occupying memories and storages. Lightweight containers share operating system and therefore, there are more rooms for softwares. It increases the capability of Cloud data centers. Furthermore, in terms of resource utilization, it provides much finer granularity operation than a VM-based Cloud model. Containers partition
% a VM into smaller chunks so that with appropriate management, better energy efficiency can be achieved. From the cloud users' perspective, each container provides separated libraries for specific application.  Therefore, it does not contrained by the underlying platform. Like PaaS, Cloud users do not need to concern the scalability of applications. 
% Therefore, CaaS can potentially become one of the main stream in the future Cloud computing industry. 

% Secondly, energy-efficent computing has been the major concern since the begining of computers. Specifially, Cloud computing has become a popular form. Large-scale data centers have been built around the world. A data center can consume huge amount of energies and it needs to improve its energy-efficiency from multiple perspectives. As we discussed in the Introduction, computing servers are one of the major contribution to the energy consumption. 
% And according to observation by \cite{}, the average utilization resource are still very low which causes huge energy wastage. As we mentioned above, the container technolgy provides a better way of managing resources, it has the potential to largly improve the utilization than current VM-based Cloud model because it avoids some of the major drawbacks of VM-based model. 

% Thirdly, because the container technology is relatively new, previous research are mostly focus on IaaS model and so that the server consolidation has based on the VM-level. However,   

% Frist is this new technology of container that can potentially change the landscape of
% Cloud computing. It has so many benefits but also it brings difficulty in managing resources.

% Second, from green computing point of view, we still need to manage resource so that, the 
% data centers consume less energy. And container technolgy actually bring a better chance to
% be more energy-efficient than previous VM based technology.
% Third, it is very difficult to manage this container-based resources because of the problem-nature is too complicated. And existed algorithms can not be directly applied on it.
% Fourth, the evolutioanry computation provides a good framework to handle such difficult problem.

% \textcolor{Blue}{Motivation is what is now lack from the literature.} \\

% The advantage of Platform as a Service (PaaS) has been discovered in the recent years. 
% The disadvantage of tranditional IaaS model has been discovered in the recent years \cite{Mann:2016hx}.
% In IaaS, on one hand, cloud customers need to manage the low-level details ranging from application capacity estimation,
% resource planning and selection and deployment. 
% On the other hand, Cloud providers manage resource provisioning and allocation. 
% Although these two tasks are seemingly different, 


% The container as a Service (CaaS) cloud model has gain increasing attention in the recent years.
% However, the energy efficiency in CaaS cloud environment has not been investigate. 
% Particularly, the virtual machine and container joint consolidation is the core problem.
% Therefore, in this thesis, we will focus on the end-to-end energy-aware server consolidation on container-based
% Cloud. In the meanwhile,  a major research direction of large scale server consolidation is also considered. 
% The end-to-end server consolidation refers to the server consolidation techniques used
% in the different stages throughout the routine Cloud resource management including  initial VM provisioning and placement, dynamic VM placement, and static VM placement:

