\section{Research Goals}

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{pics/thesisPlan.png}
	\caption{Relationship between objectives}
	\label{fig:objectives}
\end{figure}
\bx{The overall goal of this research is to optimize energy consumption of a container-based Cloud data center using EC-based approaches for three placement decision scenarios:} initial placement of application, periodic placement of application, and dynamic placement of application. The specific research objectives of this work can be itemized as follows.
% In this thesis, we aims at providing a series of approaches to continuously optimize the joint allocation of VMs and containers that considers three consolidation scenarios: Initialization, global consolidation, Dynamic consolidation. In addition, the static allocation normally involves with large amount of variables which is particular difficult to optimize. We are also going to propose a method to solve this problem.  These approaches combine element of AI planning, to ensure the objectives and constraint fulfillment, and of Evolutionary Computation, to evolve a population of near-optimal solutions. The research aims at determining a flexible way in creation of solutions to solve server consolidation problems. As discussed in the previous section, the research goal can be achieved in the following objectives and sub-objectives.

\subsection{Objective One: Develop EC-based approaches for the single objective joint placement of containers and VMs for initial placement of application}
\label{sec:obj1}

\bx{The goal of objective one is to minimize energy consumption in initial placement of application at container-based cloud.} We set three sub objectives to achieve this goal. The first sub objective is to propose a new bilevel energy model for the joint placement of containers and VMs in PMs. The second sub objective is to develop an EC-based optimization algorithm to solve the joint placement of containers and VMs. The third sub objective improves scalability of the proposed EC-based optimization algorithm. Note that, we will use ``the bilevel model/problem'' to replace ``the joint placement of containers and VMs model/problem'' in the following content. 
% \textcolor{Maroon}{Currently, most research on container consolidation do not consider the two-level of allocation problem.} Unlike previous VM-based service consolidation, 
% most research focus on VM-based server consolidation technique. They often modeled the VM allocation problem as a vector bin-packing problem \cite{Zhang:2016cx}. 
% Container adds an extra layer of abstraction on top of VM. The placement problem has become a two-step procedure, in the first step, containers are packed into VMs and then VMs are consolidated into physical machines. These two steps are inter-related to each other. Previous research \cite{Piraghaj:2015uf} solve this problem in separated steps where the first step allocates containers to VMs and the second step allocates VMs to PMs with simple bin-packing heuristics. According to Mann's \cite{Mann:2016hx} observation, these two allocations should be conducted simultaneously to reach a near-optima solution, which essentially minimizes the energy consumption.

\begin{enumerate}
	\item Develop a new bilevel energy model to represent the relationship between five factors and energy consumption. The five factors involve locations of container, types of VM, locations of VM, overheads of VM, and the balance between memory and CPU. We need to consider the interaction between these factors.
	% \textcolor{Maroon}{This problem can be considered as a bilevel problem \cite{} the lower-level optimization: allocate containers to VMs and the upper-level: allocate VMs to PMs.} 
	% \textcolor{Maroon}{Since the existing models for container-based consolidation are based on VM-based model which incurs two problems.}
	% First problem is that they did not consider the interaction between two levels of allocation.
	% Second problem is that they did not consider balancing the residual resources (e.g between CPU and memory). 
	% \bx{The goal of the first sub objective is to propose a bilevel model for the joint placement of container and VM.} 

	\bx{The major challenge of this sub-objective is that the bilevel energy model is more complicated than a single-level energy model.}
	\textbf{First}, in a VM-based model, the only factor is the locations of VMs in PMs. In contrast, in a container-based model,  the energy model involves four more variables. Specifically, locations of container decide the utilization of VMs. Types of VM constrain the placement of container. Overheads of VM bring extra workload to the PMs. The balance of CPU and memory may indirectly impact on the energy consumption. Mishra \cite{Mishra:2011bz} finds better balance leads to a higher probability of allocating more applications. The above mentioned five factors are very likely to affect the energy consumption. \textbf{Second}, two pairs of interaction have not been considered. The first pair is the interaction between containers and types of VM. The second pair is the interaction between locations of container and locations of VM. Therefore, the bilevel energy model is very complicated.

	% Three challenges are listed as follows. \textbf{First}, the bilevel energy model is more complicated than a single-level energy model. The relationship among variables of the bilevel energy model has not been explored. In the VM-based energy model, the only variable is the location of VMs in PMs. In contrast,  container-based energy model has more variables such as the location of container, type of VM and the location of VM. \textbf{Second}, the balance of CPU and memory has an impact on the energy consumption  The more balance between CPU and memory in a PM, the higher probability of being able to allocate more applications. However, in container-based cloud, defining this balance is not straightforward because an additional variable of VM type has not been considered in previous study. \textbf{Third}, the overheads of VMs has not been considered in VM-based model because there is no better way to avoid the overheads. However, in container-based cloud, the overhead of VM can be mitigated by reducing the number of VMs. Therefore, adding the overhead of VM to the container-based energy model is necessary. 

	% The first issue is that it is still unclear that which energy function is the best to capture the relationship between container and VM so that the overall energy is low. Specifically, the objective for the lower level - placing container to VM, is still unclear. This is because the minimum number of VM does not necessary lead to the minimum number PMs; the types of VM also play an important role.
	% The second issue is that previous VM-based research do not consider the overhead of VM. However, the overhead of VMs is a major source of resource wastage (addressed in Section \ref{sec:comparison_container_vm}). Therefore, how to represent the impact of VMs remains unsolved.
	% The third issue is related to a VM-based research,  Mishra \cite{Mishra:2011bz} discovered that when multiple resources are considered in the model, the balance between resources has a heavy impact on the optimization results. Therefore, in the bilevel model, the balance of resources should also be considered.

	\bx{In order to establish a bilevel energy model, we will follow three steps and gradually add factors to the energy model. } Because the correlation between the five factors are complicated, we must study their correlation pair by pair. 
	\textbf{First}, we will consider the relationship between overheads, types of VM, and numbers of VM because they are close related. In order to study the overheads of VM, we will review a number of research about VM hypervisors and study the impact of VMs. Our hypothesis is that the overheads has a linear relationship with the number of VM and has no correlation with the type of VM. The outcome of the study of overheads will be a formulation that describes the relationship between overheads, types of VM, and numbers of VM.
	% We need to solve three open questions. 
	% \begin{enumerate}
	% 	\item How to represent the overhead of VM?
	% 	\item What is the correlation between overheads and types of VM?
	% 	\item What is the correlation between overheads and the number of VM?
	% \end{enumerate}
	% We expect to formulate the relationship between overheads, types of VM, and the number of VM. 
	\textbf{Second}, we will consider the balance between CPU and memory in both VM and PM levels. Because no one has considered the balance in bilevel. We 
	will first consider formulate the balance in both levels. However, this formulation may have a high computation complexity. Hence, we will consider an aggregation of resources from both levels. Our hypothesis is that the aggregation can also achieve high utilization in PMs. The outcome of the study will be a formulation that describes the balance between CPU and memory in two levels.
	\textbf{Third}, we will consider the energy consumption with container, 
	VM, and PM. We will review a number of VM-based research \cite{Ferdaus:2014ep, Xu:2010vh, Gao:2013gg}. 
	The VM-based research generally represents the resource demand as resource utilization. 
	We can use similar idea to represent containers. The outcome of the study of overheads will be a formulation that describes the relationship between container, VM, PM, and energy consumption.
	% \begin{enumerate}
	% 	\item How to represent container, VM and PM?
	% 	\item What is the correlation between container and types of VM?
	% 	\item What is the correlation between the locations of container and VM?
	% \end{enumerate}
	
	\bx{The sub objective is expected to formulate the bilevel energy model to represent the relationship between five factors.}

	% Each level of the problem will be formulated to a multi-dimensional vector bin packing problem. 
	% We will start from the simplest case - single dimension of resource - to more general multi-dimensional resources model by reviewing a number of VM-based approaches. Specifically, we focus on their variables, constraints and objective function. Objective function is mainly related to energy consumption. Hence, energy model is another major issue to study. In addition, in the multi-dimensional resource model, we will address the balance of CPU and memory problem by investigating several resource wastage models. In this objective, we consider the static workload of applications, this is because the initial resource demand is often provided by the Cloud users.


	% The novel contribution of this sub-objective is 


	\item Propose a new EC based bilevel optimization approach to solve the initial placement of application to achieve better energy efficiency than VM-based approaches.\\
	% \bx{Based on the proposed bilevel model, the goal of this sub-objective is to develop an approach for the bilevel optimization problem using nested Evolutionary algorithms \cite{Sinha:2017et}.}

	\bx{We need to solve two challenges.} \textbf{The first challenge} is to design a representation of multiple variables for EC-based optimization approach. Current VM-based representation only contains one variable while container-based representation contains three variables: locations of container, locations of VM and types of VM. Furthermore, current VM-based research generally applied binary representation (use 0 and 1 to represent placement). However, in container-based cloud, we cannot apply binary representation because it is not straightforward to represent bilevel of placement. 
	In addition, it is difficult to design a representation that narrows down the search space of solutions.  \textbf{The second challenge} is to design genetic operators and search mechanisms for an EC-based optimization approach. Since bilevel optimization problem is known as a NP-hard problem \cite{Mathieu:2011dw}, the landscape of search space is ragged because of non-linearity, non-differentiability, non-convexity etc. Therefore, we need to further explore an effective search mechanism that can quickly locate feasible solutions.

	\bx{In order to solve these challenges, we can explore some existing approaches.} For the representation, we can review a number of VM-based research that uses direct discrete representation \cite{Xu:2010vh} and indirect continuous probability representation \cite{Xiong:2014jq}. Then, based on the bilevel of placement problem, we can learn from their representation and design our specific way of encoding and decoding such as our preliminary work in Section \ref{sec:representation}. Furthermore, in order to fast locate feasible solution, we can embed a heuristic in the representation like in Section \ref{sec:representation}. 
	Based on different forms of representation, we can investigate a few EC-based bilevel algorithms such as GA-based approach: Co-evolutionary algorithm \cite{Legillon:2012dd}, PSO-based approach: Nested Particle Swarm Optimization \cite{Li:2006br} and others \cite{Angelo:2013ee, Zhu:2006in}.
	

	% In the bilevel problem, placing containers into a minimum number of VMs does not necessary lead to the minimum energy consumption. Therefore, it is still unclear that relation among the selection type of VM, placement of container and placement of VM will affect the energy consumption. Second challenge is how to design the search operators and representation. Currently two types of representation: direct and indirect representation can be considered. However, it is unclear that which one is more suitable for the nature of the bilevel problem. Third, bilevel optimization is strongly NP-hard , the solution space can be non-linearity, discreteness, no-differentiability, and non-convexity. Therefore, it is extremely difficult to design a proper search mechanism to find near optimal solutions.

	% In order to discover the relation among the selection type of VM, placement of container and placement of VM, we will first use one type of VMs and one type of container. By controlling these variables, the effect of different types of VMs and containers will be eliminated. Therefore, the relationship between bilevel placement would be clear. We will gradually add up variables and constraints. For the representation of bilevel problem, Genetic operators are also designed along with the proposed representation.

	\bx{We will evaluate our approaches in two ways.} \textbf{First}, in order to find the most suitable representation and EC-based algorithm, we will conduct experiments on different approaches and compare their performance in terms of energy efficiency. \textbf{Second}, we will compare our algorithm with existing VM-based approaches on the same benchmark dataset. 

	\bx{The sub objective is expected to propose an EC-based approach for the initial placement of application.} We expect the proposed EC-based approach can achieve better energy efficiency than existing VM-based approaches \cite{Wilcox:2011ea, Xu:2010vh}.

	\item Improve the scalability of the proposed EC-based approach up to one thousand applications.

	The major challenge of this task is the complexity of bilevel problems and the long computation time of EC-based approaches \cite{Sinha:2017et}. 

	\bx{We can use three methods to improve the scalability.} \textbf{First}, we can reduce the number of variables by combining small containers
	into groups. We can use clustering approaches such as K-means \cite{Xie:2011fj} and decision tree to group containers. \textbf{Second}, we can separate a large question into several small questions so that they can be executed in parallel. The divide-and-conquer approach is a possible way but we need to investigate how to split the question. \textbf{Third}, we can design a hybrid EC-based algorithm mixed with heuristics. The hybrid algorithm can quickly locate the feasible solutions. For example, we can embed the representation with a First Fit heuristic. We will investigate how to design a heuristic and how the heuristics cooperate with the EC-based approach.

	\bx{We will evaluate our approach by comparing energy efficiency and execution time with the previously proposed EC-based approach.}

	\bx{The sub objective is expected to improve the scalability of the previously proposed EC-based approach up to one thousand applications without decreasing the energy efficiency.}


	% \bx{Three approaches can be potentially used in improving the scalability.} The first one is single-level reduction \cite{Sinha:2017et}, which reduces the bilevel problem into a single dimensional problem. Containers can be categorized into VMs which is then placed into PMs. The combination of container must be based on the knowledge of two-level placement interaction which we discover in the previous objective.  Then, complementary containers can be grouped to reduce the variables of placement. The challenge is to identify the features of static workload so that different workloads can be combined to fill a VM. Another way is use reinforcement learning to learn the pattern of energy-efficient combination of containers. 
	% The second approach is using a divide and conquer method to split the large number of containers into smaller chunks. The main challenge is that how to split the problem is unknown. Randomly dividing is very likely lead to a sub-optimal solution.
	% The third approach is combine heuristics into the EC algorithm, for example, develop a representation which is embedded with a simple heuristic (e.g First Fit). The heuristic is expected to reduce the search space so that the EC algorithm can find solution more efficiently. However, design a heuristic which embedded inside an EC algorithm is extreme difficult since evaluation of heuristic is indirect. 

	% \item Third, although nested approaches have been reported effective, they are often very time consuming. Therefore, our third sub-objective will focus on developing more efficient algorithms. There are several possible directions to be explored such as metamodeling-based methods \cite{Wang:2007em} and single-level reduction. 
		% \emph{New operators and searching mechanisms}\\
		% In order to utilize Evolutionary Computation (EC) to solve this problem, we are going to develop searching mechanisms according to the nature of problem as well as the selected representation. In order to achieve this goal, we will design several new operators. In order to evaluate the quality of these components, we will perform analytical analysis on the result.
\end{enumerate}
\subsection{Objective Two: Develop an EC-based approach for the multi-objective periodic placement of application}
\bx{The goal of this objective is to develop a multi-objective EC-based approach for periodic placement of application at container-based cloud with consideration of various types of workload.} Two objectives are minimizing the energy consumption and minimizing the migration cost.
We set four sub objectives to achieve this goal. The first sub objective proposes a multi-objective bilevel model for periodic placement of application taking into consideration with static workload. The second sub objective proposes an EC-based multi-objective algorithm with Pareto front approach. The third sub objective extends the previous multi-objective model with consideration of three types of workload: static, continuously increasing, and periodic. The fourth sub objective extends the previous EC-based multi-objective algorithm to adapt to various workloads.
% As previously (see Section  \ref{sec:motivation}) mentioned, the task is multi-objective: minimizing the number of migration and minimizing the overall energy consumption. This two objectives are conflicting since intensive optimization may incur a large number migration. The first challenge is how to solve the multi-objective bi-level optimization problem. In addition, we consider propose a robust periodic placement of application which means the placement of applications does not affect much from the variant workloads. Therefore, we divide workloads into five categories according to Fehling \cite{Fehling:2014tl}: static, periodic, once-in-a-life-time, continuously changing, and unpredictable. Among five types of workloads, two of them:  once-in-a-life-time and unpredictable workloads are unsuitable for static placement, since their behavior are hard to foresee and plan, hence, they are normally solved by dynamic approaches which will be addressed in our third objective.  For static, periodic, and continuously changing workload, we are going to design specific solutions. We also use three questions to guide our objective.
% The robustness of a data center is particularly important. 
% The robustness measures the stableness of result of consolidation.
% Furthermore, we will investigate proactive approaches - considering future allocation.
% In order to measure the degree of robustness, we need to design a robustness measure. The second sub-objective is to design static consolidation algorithm with considering its previous immediate result. The third objective extends the second objective to a more general case, considering both previous immediate and next allocation. The evaluation of algorithm is based on analytical analysis of fitness functions and robustness measure. 

\begin{enumerate}
	\item Propose a multi-objective bilevel model for periodic placement with consideration of static workload.  Two objectives are minimizing the energy consumption and minimizing the migration cost. \\

	\bx{The main challenge is that the additional migration model in container-based cloud is much complicated than VM-based cloud.}
	\textbf{First}, in VM-based cloud, many research only considers the number of migrations \cite{Murtazaev:2014eo}. In container-based cloud, because the sizes of container vary in a wide range (e.g from MBs to GBs), it is unfair to simplify the migration cost as the number of migrations. Therefore, we must consider more factors such as network bandwidth in modeling the migration cost which makes the model difficult. \textbf{Second}, container-based migration model not only considers migration of VM, but also migration of container. Therefore, adding the migration model into our previous bilevel model is difficult. 

	\bx{In order to solve these challenges,} \textbf{first}, we will explore some VM-based migration models and investigate the relationship between network bandwidth and utilization of resources in VM. \textbf{Second}, we will formulate the relationship between migration cost and the utilization of resources in two levels: VM and PM. 

	\bx{The sub objective is expected to formulate the bilevel model to represent both energy consumption and migration cost in container-based cloud.}

	% Because both container and VM can be migrated, it is unclear that migration model should be added to both layer or just one. One possible solution is to represent all VM migration with container migration. It may reduce the complexity. In addition, majority traditional migration models only consider the migration number without including the size of the applications which is unrealistic. Because the size will affect the overhead on the networking. 
	% The second challenge is to adapt the model to various types of workload. Previously, we simply the problem as applications can be represented as static workloads. In this sub objective, we consider three types of predictable types of workload: static, linear continuous changing and periodic workload. These workloads may be represented as a function of time. Other models may also be changed accordingly.

	% We will further develop an EC-based multi-objective algorithm with aggregation approach to test the model. The aggregation approach turns a multi-objective problem into a single-objective problem by combining objectives into a single one. Therefore, we may use previous developed algorithm to solve periodic placement of application problem. We will use static workload to test the model. 

	\item Propose a multi-objective bilevel EC-based algorithm for periodic placement of application with Pareto front approach to achieve better performance than VM-based approach in both energy efficiency and migration cost.\\

	\bx{We need to solve three challenges.} \textbf{First}, the relationship between the two optimization objectives is very complicated. Since both migration cost and energy consumption can be non-convex, we cannot easily imagine the trade-off between two objectives. \textbf{Second}, we must design genetic operators to adapt bilevel multi-objective optimization. Specifically, genetic operators in both levels collaborate with each other. Hence, it is more difficult to design the collaboration of operators between two levels.  \textbf{Third}, after obtaining a set of non-dominated solutions, we need to further design a fitness function assessment. The assessment selects one solution from a large number of non-dominated solutions based on some predefined preferences from Cloud providers. The selection of solution can be a difficult task for the large size of non-dominated set \cite{Zio:2012jz}. 

	\bx{We will follow three steps to solve the above challenges.} \textbf{First}, to study the relationship between two objectives, we may visualize the relationship by using a technique called Trade-off region map \cite{Pinheiro:2015eu}. The trade-off region map can identify local and complex relationships between objectives, gaps in the fitness landscape, and regions of interest. \textbf{Second}, for designing genetic operators, based on previously designed representation, we will add trade-off control mechanisms such as non-dominated sorting into the genetic operators. \textbf{Third}, in order to design a fitness function assessment, we will review some priori and posteriori decision making support methods such as Guided Multi-objective Genetic Algorithm \cite{Jat:2011us} and a clustering approach \cite{Zio:2011iq}.

	\bx{We will evaluate our algorithm by comparing with existing VM-based approaches on the same benchmark dataset.}

	\bx{The sub objective is expected to propose a multi-objective bilevel EC-based approach that can achieve better energy efficiency and migration cost than VM-based approaches.}

	% The major challenge in this sub-objective is to design genetic operators so that the proposed algorithm can steer the search close to the correct Pareto front. The aggregation approach proposed in previous sub objective has some defects such as it cannot find the non-convex solution. A Pareto front approach is able to find a set of trade-off between objectives, therefore, we decide to explore this direction. Currently only a few research \cite{Yin:2000bt, Deb:2009jh,Deb:2010in} focus on bilevel optimization problem. This will be the first time that bilevel optimization with Pareto front approach is applied on a bilevel bin packing problem.
	% However, most of them are designed for continuous problems. Therefore, new representations and operators need to be considered for discrete problem. 

	% The assumptions for this objective, we will start from one dimensional of resource: CPU utilization. We will consider the static workload in this sub objective because they are common and easy to start with.  We can utilize the representation and problem models from previous objective. However, we need to propose new genetic operators to adapt the multi-objective problem.

	% like the case in single objective problem, we need to develop new representations, genetic operators.
	\item Extend the bilevel multi-objective model for adapting three types of predictable workload \cite{Fehling:2014tl}: static, linear continuously changing, and periodic. \\
	
	\bx{The major challenge for this objective is the complexity of modeling three types of workload.} 
	Even though we can roughly categorize workloads into three types, practically, workloads are still full of uncertainty and noise. 

	\bx{We may try several ways to represent workloads uniformly.} \textbf{First}, we may consider modeling workload as a function of time. \textbf{Second}, we may apply time-series analysis techniques on workloads so that three types of workload can be represented as their features.
	% Factor analysis such Principle Component Analysis \cite{Wold:1987wx} can be employed in developing new measure. Meanwhile, the representation used in static workload might not work, therefore, new representation, genetic operators need to be developed. 

	% Proactive consolidation \cite{Farahnakian:2015vj, Tan:2011jd} has driven a lot of attention in recent years. They mainly focus on making prediction of the workloads using a regression approach such as linear regression, multi-linear regression, and K-means regression. However, most of their consolidation methods are simple heuristics. In our approach, we seek to propose a combined technique.

	% \item Second, we will design a robustness measure. Previous studies only use simple measurement which counts the migration number between two static consolidation. This measurement aims at minimizing the number of migration between two  static placement processes. It may cause more migration in the next consolidation. Therefore, it needs a time-aware measure of the robustness of system. Therefore, in this objective, the first sub-problem we are going to solve is to propose a robustness measure. Currently, only a few research propose robustness aware server consolidation techniques \cite{Takouna:2014fa, Grimes:2016ia} have been proposed. They are either static threshold or probability-based threshold to measure the robustness of PMs. We will investigate an adaptive measure based on the historical data and current status.

	\bx{The sub objective is expected to extend previous bilevel multi-objective model to adapt to three types of workload.}
	
	\item Extend the previous EC-based multi-objective algorithm to adapt to various of workload.

	\bx{The major challenge for this objective is to design representations and genetic operators to adapt to three types of workload.} Different representations may be suitable for different types of workload. Therefore, it is possible to design three distinct representations for three workloads. In addition, we must design search mechanisms to collaborate with the representations.

	\bx{In order to find the most suitable representation and EC-based algorithm, we will conduct experiments on different approaches and compare their performance in terms of energy efficiency.}

	\bx{The sub objective is expected to extend a multi-objective bilevel EC-based approach to three types of workload.}
	
	% \item \emph{Design a }\\

		% We will generalize the previous sub-objective to a more general one: design a time-aware allocation method which takes previous and next allocation into consider.
	\end{enumerate}




\subsection{Objective Three: Develop a hyper-heuristic single-objective Cooperative Genetic Programming Hyper-heuristic (GP-HH) approach for automatically generating dispatching rules for dynamic placement of application.}

\bx{The goal of this objective is to develop a cooperative GP-based hyper-heuristic algorithm so that the generated dispatching rules can achieve both fast placement and global optimization with five types of workloads.} We set three sub objectives to achieve this goal step by step. The first sub objective proposes a GP-based hyper-heuristic (GP-HH) algorithm for automatically generating dispatching rules for the single-level placement: container to VM with static workload. The second sub objective extracts features on the predictable workloads and two additional unpredictable workloads to construct a new primitive set. The third sub objective develops a cooperative GP-HH approach for automatically generating dispatching rules for placing both containers and VMs.

% Previously, dynamic consolidation methods,including both VM-based and container-based, are mostly based on bin-packing algorithm such as First Fit Descending and human designed heuristics. As Mann's research \cite{Mann:2015ua} shown, server consolidation is more harder than bin-packing problem because of multi-dimensional of resources and many constraints. Therefore, general bin-packing algorithms do not perform well with many constraints and specific designed heuristics only perform well in very narrow scope. Genetic programming has been used in automatically generating dispatching rules in many areas such as job shop scheduling \cite{Nguyen:2014eu}. GP also has been successfully applied in bin-packing problems \cite{Burke:2006ei}. Therefore, we will investigate GP approaches for solving the dynamic consolidation problem. We will start from considering one-level of problem: migrate one VM each time to a PM. 

% Therefore, in this objective, we will use GP to automatically generate heuristics or dispatching rules.

\begin{enumerate}

	\item Develop a GP-based hyper-heuristic (GP-HH) algorithm for automatically generating dispatching rules for the single-level placement: container to VM with static workload. \\
	\bx{In order to develop a cooperative GP-based hyper-heuristic to the bilevel problem, it is necessary to develop a GP-HH for the single-level placement first.} Then, two GP-HH can collaborate with each other.

	\bx{Two major challenges,} \textbf{first}, it is difficult to design a hyper-heuristics to generate dispatching rules. We must explore meaningful features of static workload, VM, and PM to construct a primitive set. It is uncertain which feature can contribute to the dispatching rule.  \textbf{Second}, it is even difficult for the generated dispatching rules to reach a global optimal solution because of the trade-off between training accuracy and over-fitting.

	\bx{To gradually solve above challenges,} \textbf{first}, we may start from considering the features such as the status of VMs (e.g resource utilization), features of workloads (e.g resource requirement) that will affect the placement decision. The above features are represented as resource utilization. We will construct a primitive set with the selected features. 
	\textbf{Second}, we will use the default function set and the basic tree representation for constructing the dispatching rules. 
	\textbf{Third}, to train the GP-HH, we will use the solutions from the first objective as the learning sets. We may use ten folds cross-validation to prevent from over-fitting. 

	\bx{In order to evaluate the automatically generated heuristics, we will use a widely used simulator called CloudSim \cite{2009LNCS.5931...24B}.} Since our proposed algorithm is equivalent to the VM-based placement algorithm because they both focus on single-level of placement. We will compare our heuristic to a highly cited work \cite{Beloglazov:2012ji} from Beloglazov who proposes a Best Fit Decreasing heuristic for the energy consumption problem.

	\bx{The sub objective is expected to propose a GP-HH algorithm for automatically generating dispatching rules for the single-level placement with static workload.} The generated dispatching rules are expected to achieve equal or better performance than manually designed heuristics in terms of energy efficiency. 

	\item Conduct feature extraction on the three predictable workloads and two unpredictable workloads to construct a new primitive set. \\
	
	\bx{The major challenge is to discover useful features that can represent various workloads.} The first challenge is to identify features from high dimensionality of datasets. The raw workload dataset may contain a large number of data points. It is difficult to extract meaningful features from the data points. The second challenge is to select useful features from a large number of raw features. It is very time consuming to manually examine raw features. The correlations between these raw features bring additional complexity.

	\bx{To solve these challenges, } \textbf{first}, we will review a number of dimensionality reduction techniques. Some possible techniques are sampling, extrema extraction. \textbf{Second}, we may employ the principle component analysis (PCA) technique on the features set to reduce the number of features. 

	\bx{Classification of various workloads is one of the way to test the extracted features}. If we can differentiate workloads according to extracted features with a high accuracy (e.g. 95\%), the features can be used in generating new dispatching rules. 

	\bx{The sub objective is expected to extract a number of features to represent different types of workload.} We can apply these features to construct a new primitive set so that the dispatching rules can deal with all kinds of workload.}


	% types including static, continuously changing, and periodic workloads, and two other workload types: once-in-a-life-time, unpredictable workloads. Based on these features, 
	% \textcolor{Blue}{More...}
	% \item Investigate the possible functional operators. 

	% \bx{The goal of this sub-objective is to construct a GP functional set.}
	% \textcolor{blue}{More will come.}

	\item Develop a cooperative GP-HH approach for automatically generating dispatching rules for placing both containers and VMs. \\
	\bx{The major challenge is to develop a cooperating procedure between two GP-HHs on two levels.} 
	As the first step, we will consider using two sub-populations to represent two-levels of placement. Each sub-population would be trained to minimize their objectives. The second step,the subpopulation in the container-VM level will be used in training the VM-PM level of placement. 

	\bx{This sub objective is expected to propose a cooperative GP-HH approach for automatically generating dispatching rules for dynamic placement in container-based cloud.}

	% This sub-objective explores suitable representations for GP to construct useful dispatching rules. It also proposes new genetic operators as well as search mechanisms. \textcolor{blue}{More will come.}

	\end{enumerate}

% \subsection{Objective Four (Optional) Large-scale Static Consolidation Problem}
% Propose a preprocessing method to eliminate redundant variables 
% Current static consolidation takes all servers into consider which will lead to a scalability problem. In this objective, we will investigate two branches of methods, first one categorizes a number of containers into fewer groups so that the granularity decreases \cite{Piraghaj:2015uf}. Second method categorizes PMs so that only a small number of PMs are considered. This approach will dramatically reduce the search space. The potential approaches that can be applied in this task are various clustering methods.

	% The 
	% initial placement can be considered as a two-level of multi-dimensional bin-packing problem with multi-objectives. 
	% \item First, from the perspective of \emph{Cloud resource allocation model}, 
	% 	traditional Infrastructure as a Service (IaaS) resource allocation model 
	% 	considers service allocation and VM placement as separated responsibility.
	% 	Cloud users or brokers need to concern about the resource mapping and VM selection and 
	% 	Cloud providers take care of the VM placement. 
	% 	However, as Cloud users tend to over-provision in order to satisfy the QoS, they often book more
	% 	resources than their need. This is the major reason for the low utilization in 
	% 	Cloud computing \cite{Vogels:2008bg}. This problem cannot be 
	% 	resolved solely from the Cloud providers' perspective but to change the current resource allocation model. In the new resource allocation model, the responsibility of service allocation and VM placement are in the same hand of the Cloud provider.
	% 	Thereafter, Cloud providers have the full control of resource management. 
	% 	However, this process makes the VM initial placement a more complicated problem. Currently, only few researchers \cite{} have noticed this problem and propose initial work to address this problem.
	% \item Dynamic server consolidation is the process that the resource management continuously detects the server runtime status and if one of the server is overloaded. Then,
	% one of the VM or container running inside the server will be migrated to other machine 
	% so that the applications do not suffer from a performance degradation. In a container-based
	% environment, there are three questions to be answered. \emph{When to migrate ?} refers to determine the time point that a physical server is overloaded. \emph{Which container to migrate?} refers to determine
	% which container need to be migrated so that it optimize the global energy consumption.
	% \emph{Where to migrate?} refers to determine which VM and host that a container is migrated to.  
	% Specifically, in the second question, the main idea in the literature is still simple heuristics and random selection. Therefore, we are going to investigate using a genetic programming technique to learn to choose the best. In the 
	% third question, literature also rely on simple bin-packing heuristics which do not consider the impact of environment. Therefore, we are going to propose an idea which uses the features of workload, to decide which VM
	% is the best choice.

	% \item Static server consolidation is the process that a batch of VM and container joint is
	% consolidated in order to achieve an low energy consumption status. This stage is often
	% applied when the overall energy consumption is reached a predefine threshold. The static
	% server consolidation can globally optimize the energy consumption of the data center.
	% The process is similar with the initialization stage but with different objectives and constraints.

	% \item 

	% \item Second, container as a service has become an important trend in the 		Cloud computing industry and being support by many Cloud providers 	such as Amazon, Azure and many 
	% 	open-source projects. Both Cloud users and providers 
	% 	are beneficial to its lightweight. It provides a finer granularity resource management
	% 	for Cloud providers. From Ref \cite{}, we observed that VM-level consolidation could further improve the utilization of resource as well as the footprint from traditional hypervisors. 
	% 	However, there is not much container consolidation methods were discussed in the literature. 
	% 	New models and consolidation methods need to be proposed to solve the problem. Moreover, similar to
	% % 	VM placement, container placement is also an multi-objective which need to be addressed.

	% \item Third, the joint VM and container poses another level of consolidation problem. Ref \cite{} states, 
	% 	one of the reasons that container consolidation has high SLA violations is because the 
	% 	higher migration rate of containers. Therefore, designing algorithms that dynamically select between VM and container migration based on application SLA requirement as well as the impact on energy consumption is the major concern of the joint allocation. This can be treated as a dynamic task. 

	% \item Fourth, a common problem that faced by both traditional VM-based and the recent container-based data 	center is the affinity aware resource allocation problem. 
	% 	Modern Cloud-native applications normally have more than one copy of its implementation called replica in order to resolve the stateless as well as load balancing problem. Hence, they must be allocated into different servers to maintain its reliability. Similarly, the backup of databases has the same issue. In the CaaS scenario, more constraints appear such as operating system aware allocation which means, 
	% 	certain container can only be allocated in a specific operating system \cite{}. 
	% 	The affinity-aware allocation has been discussed in the literature, 
	% 	however, they can only be applied in the VM-based data center.   
	% \item Fifth, a resource-utilization aware co-location scheme can be helpful in order to resolve the 
	% 	resource competition problem. The study is about the behavior of the applications deployed
	% 	in the same physical machine. The previous research assumes that the applications' behavior
	% 	is a priori \cite{}, however, applications' behavior can be changed over time. It is important to allocate
	% 	the compatible applications in the same physical machine so that the physical machine reaches a 
	% 	stable status.

	% \item Sixth, large scale of server consolidation has always been a challenge in a Cloud data center. 
	% 	Especially, typical number of servers in a data center is at the million-level. Many approaches 
	% 	have been proposed in the literature to resolve the problem. 
	% 	There are mainly two ways, both rely on distributed methods, 
	% 	hierarchical-based \cite{} and agent-based management systems \cite{}.
	% 	The major problem in agent-based systems is that agents rely on heavy communication to maintain a high-level utilization. Therefore, it causes heavy load in the networking. Hierarchical-based approaches are the predominate methods. Hierarchical-based methods, in essence, are centralized systems where all the states of machines are collected and analyzed. One of way to improving the effectiveness of centralized system is to reduce the size of variables without losing too much of the consolidation performance. The main idea is to eliminating the high-utilized servers so that it reduces the dimensionality. 
% \end{enumerate}