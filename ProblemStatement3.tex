% Hopefully this will be the final version of Problem statement.
This chapter introduces this research proposal. It starts with the problem statement, then outlines the motivations, research goals and the organisation of this proposal.

\section{Problem statement}

% \bx{what is cloud computing and why it is the pillar of software and other related industry. (importance of cloud computing.)}
% \bx{
% \begin{itemize}
% 	\item (what) the main challenge for cloud provider is to reduce energy consumption
% 	\item why it is important and so what? (consequences?),
% 	\item how to deal with it? (technologies)
% \end{itemize}}
\bx{Cloud computing has made a huge impact on modern software industry by offering on-demand computing capacity (e.g storage and computing) \cite{2010arxiv1006.0308b}.} Compare with traditional software industry, web service providers such as Google and Neflix do not need to build data centers and manage hardware resources. They can develop, deploy and maintain applications (e.g. google drive) on cloud \cite{adhikari:2012uq} without worrying about scalability issue (e.g. dynamically increases the capacity of application) and availability of applications (e.g services are accessible 99.99\% of the time). For application users, they can enjoy applications without experiencing breakdown and access the applications from anywhere in the world.

\bx{A major issue in cloud computing is the huge energy consumption generated by data centers} - a typical data center consumes as much energy as 25,000 households \cite{dayarathna:2016ua}. Huge energy consumption has become the major expense of cloud providers. The reduction of energy bill will be further beneficial to the profit in software industry as well as most people who access the Internet on a daily basis with a lower cost.

\bx{Generally, reducing the energy consumption of a data center can be achieved by reducing the number of live physical machines (PMs) (e.g. servers).} Studies shows \cite{Barroso:2007jt, Shen:2015hm}, among several energy consuming components such as cooling systems, PMs, and network devices, PMs account for the majority - more than 40\% - of energy consumption while these PMs are not used effectively. The proportion of PMs' average utilization is quite low - from 10\% to 50\% due to some disadvantages in resource management. Therefore, it is possible to reduce energy by improving the utilization of PMs.
% This is because cloud users tend to preserve more resources in order to guarantee the performance when facing the variation of workloads.

\bx{The common way to improve the utilization of PMs of a data center is through resource management of PMs \cite{Manvi:2014hm} (see Figure \ref{fig:workflow}).} The cloud resource management of PMs is a centralized system \cite{Jennings:2015ht} that allocates resources such as CPUs and memories of PMs to cloud users' applications and handles the workload fluctuations. Four major steps in resource management are listed as follows: Collecting utilization data from PMs, analyzing available resources on PMs, deciding the placement of applications on PMs, and executing the application placement decisions.  As better allocation of CPUs and memories leads to the reduction of energy consumption, the placement decision is the most important step.

\bx{Placement decision is applied in three scenarios to improve the utilization of PMs.} Three placement decision scenarios are common in a data center: application initial placement handles new arrival of applications; periodic optimization adjusts the placement globally and periodically; dynamic placement adjusts application in a fast manner. All three decision scenarios rely on an optimization strategy called server consolidation. 
\begin{figure}
	\centering
	\includegraphics[width=0.7\textwidth]{pics/workflow_management.png}
	\caption{A workflow of resource management \cite{Mishra:2012kx}}
	\label{fig:workflow}
\end{figure}

% Data collection gathers resource utilization information from individual PMs and VMs such as CPU, memory utilization in a period of time. These data are collected by monitoring softwares for data analysis. Data analysis takes the collected data as the input, cleans and analyzes them. It outputs the quantity of demand resources of applications. Finally, execution places the applications to the target PMs. 

% \bx{Among these resource management steps, placement decision is the crucial step which includes three scenarios: application initial placement, periodic optimization and overloading & under-loading adjustment.} Essentially, these three scenarios contain a common strategy called server consolidation.


\bx{Server consolidation \cite{Varasteh:2015fu} is a strategy to manage the resources of PMs by placing applications in fewer PMs and lead to lower energy consumption.} For three resource management scenarios, they are generally considered as two types of problem: static and dynamic. Static problem is solved in an off-line fashion which includes application initial placement and periodic optimization, while dynamic placement problem is solved in an on-line fashion. In order to solve static and dynamic problems, server consolidation strategy must also be designed in static and dynamic fashions. 


\bx{Currently, resource management in data centers is based on \emph{virtualization} technology\cite{Uhlig:2005do}. } Such virtualization separates the resources (e.g. CPUs and RAMs) of a PM into several parts called \emph{virtual machines (VMs)}, each of VMs runs an isolated operating system. Compare with virtualization, the traditional data center assigns a PM for each application; it leads to the low reserved utilization of PMs. After the technique of VM being introduced, the multiplexing of PMs largely improve the utilization and reduce the energy consumption. 

\bx{However, in recent years, resource management with VMs cannot catch up with a new trend in software industry - Service Oriented Architecture (SOA) \cite{Sprott:2004wt};} SOA has become widely used in modern software industry because of its agility and re-usability \cite{Sprott:2004wt}. SOA separates a centralized application into multiple distributed components called web services. As most of web services only require a small amount of resources,  using a VM for a web service causes resource wastage inside a VM. Consequently, the low utilization of PMs decreases the energy efficiency. To support the architecture of SOA and further reduce energy consumption, a new virtualization technology: containers \cite{Felter:2015ki, Soltesz:2007cu} has been proposed. The container technology provides a new architecture for allocating applications and a finer resource management which has the potential to further improve the energy consumption.

\bx{A container is an operating system (OS) level of virtualization which runs on top of VMs.} Similar to VM, a container provides performance and resource isolation for a single application. Different to VMs, multiple containers can run in the same VM without interfering each other. In addition, containers naturally support vertical scaling (change its size during runtime)\cite{Vaquero:2011gb} which is resilient to fluctuate workloads. However, vertical scaling requires the VMs to reserve enough resource to support the increasing size of container.

\bx{Although the efficient use of containers can improve the utilization of VMs, it brings new challenges and difficulties to server consolidation \cite{:2017ff}.}
Current VM-based server consolidation strategy cannot be directly on container-based cloud because of the different application placement structure. This research aims at improving the utilization of PMs in container-based cloud by proposing new bilevel energy models and server consolidation algorithms for three placement decision scenarios: application initial placement, periodic optimization, and dynamic placement.

% In summary, in order to improve energy efficiency in container-based data center, this research aims at proposing new models and algorithms for three placement decision scenarios:application initial placement, periodic optimization, and dynamic placement. In the following section, we will discuss the challenges in these scenarios.

% \bx{Despite which virtualization is used, server consolidation can be applied in three resource management scenarios:} application initial placement  \cite{Jennings:2015ht}, periodic optimization \cite{Mishra:2012kx} and overloading/under-loading adjustments \cite{Mishra:2012kx} (see Figure \ref{fig:workflow}).

 % Server consumption is essentially an optimization task where it adjusts applications' locations in PMs so that a minimum number of PMs is used. For a certain number of applications, the fewer number of PMs is used, the less energy is consumed. 

% Three management processes: application initial placement, periodic optimization ,   have distinct characteristics, hence, the server consolidation techniques applied on them can be roughly classified into two categories: static \cite{Xiao:2015ik} and dynamic \cite{Beloglazov:2012bw}.

% \bx{In Initial application placement, the consolidation can be described as a static task conducted in an off-line manner.} 
\vspace{5mm}
